{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library imports\n",
    "import csv\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NDP file (~3GB of plain text)\n",
    "ndp_file = \"/Users/caoimherooney/Desktop/227-www-ndp-ca.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the NDP plain text as a dataframe\n",
    "df = pd.read_csv(ndp_file, sep = \",\", usecols=[0,1,2,3], header=None, error_bad_lines=False, quoting=csv.QUOTE_NONE)\n",
    "df = df.sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is too much data in this dataframe!\n",
    "# let's focus just on the homepage\n",
    "# find a homepage to focus on for the diffs\n",
    "homepages = df.loc[df[2] == \"http://www.ndp.ca/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's begin by comparing texts\n",
    "# we can load the SequenceMatcher library\n",
    "\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# byte-wise metric\n",
    "# compares two pages character by character\n",
    "# returns 1 if there is any change at all between two pages\n",
    "\n",
    "bytewise = []\n",
    "for y in range(len(homepages)-1):\n",
    "    first_page = \"\".join(homepages.iloc[y].tolist()) # convert webpage text into one long string\n",
    "    second_page = \"\".join(homepages.iloc[y+1].tolist()) \n",
    "    if len(first_page) == len(second_page):\n",
    "        for k in range(len(first_page)):\n",
    "            if first_page[k] != second_page[k]:\n",
    "                bytewise.append(1)\n",
    "                break   \n",
    "            elif (k == len(first_page) - 1) and (first_page[k] == second_page[k]):\n",
    "                bytewise.append(0)\n",
    "    else:\n",
    "        bytewise.append(1)\n",
    "\n",
    "# output is the list of metric values: either 0 (no change) or 1 (any change)\n",
    "print(bytewise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.220446049250313e-16, 2.220446049250313e-16, 0.021054989627438903, 0.0, 0.0540946970730829, 0.42264973081037416, -2.220446049250313e-16, 0.0, 0.4522774424948339, 0.3930230213331162, 0.44529980377477085, 0.25464400750007, 0.14160492472104802, 0.23623738417402662, 0.19096016504410962, 0.2499999999999999, 0.24738219099361825, 0.25, 0.4522774424948339, 0.28388512596056714, 0.2132042075305568, 0.26620061429465713, 0.3377338214674781, 0.3675444679663241, 0.20000000000000018, 0.10557280900008414, 0.12294198069297069, 0.08013378899220003, 0.07417990022744858, 0.20740607609878292, 0.4522774424948339, 0.14188366967896693, 0.09861218113400261, 0.125, 0.03923107716947705, 0.15384615384615374, 0.16333997346592444, 0.21553545944726393, 1, 0.4023856953328032, 0.3675444679663241, 0.16794970566215628, 0.5635642195280153, 0.47521642859401036, 0.4729537233052702, 0.23528088709812756, 0.37639043553767637, 1, 0.683772233983162, 0.683772233983162, 0.029274656605849048, 0.12294198069297069, 0.05237744552637069, 0.031754163448145856, 0.0871290708247231, 0.05719095841793653, 0.40655757394379166, 0.07355421920734462, 0.30611133351128905, 0.031754163448145856, 0.09861218113400261, 1, 0.3675444679663241, 0.17789169267941518, 0.3264246859454366, 0.04242020472052299, 0.13663128510562317, 0.5449842448067099, 0.2783121635129677, 0.0540946970730829, 1, 2.220446049250313e-16, 1, 2.220446049250313e-16, -2.220446049250313e-16, 0.6666666666666667, 0.2254033307585166, 0.0, 0.19999999999999996, 2.220446049250313e-16, 0.8377785788692375, 0.7226499018873854, 2.220446049250313e-16, 0.27831216351296784, -2.220446049250313e-16, 1, 0.3675444679663241, 1, 0.3675444679663241]\n"
     ]
    }
   ],
   "source": [
    "# TF.IDF metric\n",
    "# compares the occurrence of chosen words in each page\n",
    "# generates vectors weighted by such occurrences and calculates cosine distance between them\n",
    "\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "tfidf = []\n",
    "for y in range(len(homepages)-1):\n",
    "    first_page = re.sub(\"[^\\w]\", \" \",  \"\".join(homepages.iloc[y].tolist())).split()\n",
    "    second_page = re.sub(\"[^\\w]\", \" \",  \"\".join(homepages.iloc[y+1].tolist())).split()\n",
    "\n",
    "    # generate random list of words of length >= 5 that appear in first page\n",
    "    random_words = []\n",
    "    for i in range(10):\n",
    "        rand = random.choice(first_page)\n",
    "        while len(rand) <= 4:\n",
    "            rand = random.choice(first_page)    \n",
    "        random_words.append(rand)\n",
    "    \n",
    "    # count how many times random words appear in each page\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "    for j in range(len(random_words)):\n",
    "        v1.append(first_page.count(random_words[j]))\n",
    "        v2.append(second_page.count(random_words[j]))\n",
    "    \n",
    "    if np.linalg.norm(v2) == 0:\n",
    "        D = 1\n",
    "    else:\n",
    "        D = 1 - np.inner(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "    tfidf.append(D)\n",
    "\n",
    "# output is the list of metric values between 0 (very similar) and 1 (very different)\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002325581395348837, 0.0011627906976744186, 0.0011627906976744186, 0.0011627906976744186, 0.002325581395348837, 0.1267605633802817, 0.0010141987829614604, 0.002028397565922921, 0.41021548284118114, 0.23275862068965517, 0.4267399267399267, 0.3869346733668342, 0.22781065088757396, 0.5180851063829788, 0.5, 0.3263525305410122, 0.31356693620844567, 0.2268199233716475, 0.3921951219512195, 0.398422090729783, 0.20814132104454686, 0.22344610542879623, 0.4748858447488584, 0.5545073375262054, 0.21248499399759904, 0.12749213011542498, 0.12493268712977922, 0.15263983272347098, 0.15626560159760358, 0.20020964360587, 0.2292358803986711, 0.26662444585180495, 0.14487632508833923, 0.14931906614785992, 0.14557889594528578, 0.1411351079859367, 0.14461994076999013, 0.11724806201550388, 0.8921124206708976, 0.8498727735368957, 0.26651818856718634, 0.23558368495077356, 0.36596523330283626, 0.3399915002124947, 0.25690140845070425, 0.25314285714285717, 0.2769709543568465, 0.8818525519848771, 0.8329207920792079, 0.6790540540540541, 0.6670967741935484, 0.23282442748091603, 0.1506849315068493, 0.16413662239089183, 0.17406749555950266, 0.05802357207615594, 0.5655963302752294, 0.2941401761777097, 0.1423948220064725, 0.11659436008676789, 0.13206491326245104, 0.9127272727272727, 0.9433817903596021, 0.26140202702702703, 0.42564841498559075, 0.3988795518207283, 0.20596648957907643, 0.4920886075949367, 0.4429868819374369, 0.12802275960170698, 0.8120300751879699, 0.5891891891891892, 0.5945945945945946, 0.6363636363636364, 0.0058823529411764705, 0.6363636363636364, 0.9140164899882215, 0.0, 0.4286912751677852, 0.34280792420327305, 0.6947141316073355, 0.6096256684491979, 0.7984084880636605, 0.26621160409556316, 0.004032258064516129, 0.735191637630662, 0.832183908045977, 0.825287356321839, 0.8399122807017544]\n"
     ]
    }
   ],
   "source": [
    "# edit distances metric\n",
    "# number of edits that are required to transform one sentence into another.\n",
    "# we normalise this number by the total number of characters in each of the two pages \n",
    "# ie deleting all of page 1 and adding all of page 2\n",
    "\n",
    "edit_distances = []\n",
    "for y in range(len(homepages)-1):\n",
    "    first_page = \"\".join(homepages.iloc[y].tolist()) # convert webpage text into one long string\n",
    "    second_page = \"\".join(homepages.iloc[y+1].tolist()) \n",
    "    len_first = len(first_page)\n",
    "    len_second = len(second_page)\n",
    "    \n",
    "    distance = nltk.edit_distance(first_page, second_page, transpositions=False)\n",
    "    edit_distances.append(distance / (len_first + len_second))\n",
    "\n",
    "# output is the list of metric values between 0 (very similar) and 1 (very different)\n",
    "print(edit_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.2673733804475854, 0.0, 0.0, 0.7981340118744699, 0.7294281729428174, 0.7347740667976425, 0.7003257328990228, 0.5727699530516432, 0.7251732101616628, 0.6795180722891566, 0.7332089552238805, 0.7305101058710298, 0.5905767668562145, 0.7266035751840167, 0.6744680851063829, 0.5684039087947883, 0.5538847117794486, 0.6807980049875312, 0.8590909090909091, 0.4183417085427136, 0.3471615720524017, 0.37745372966909707, 0.3561718325176726, 0.40902021772939345, 0.5070883315158125, 0.30817610062893086, 0.36345514950166113, 0.3917147351861563, 0.40262361251261347, 0.35022807906741005, 0.323943661971831, 0.39856557377049184, 0.3346733668341708, 0.9591836734693877, 0.9606741573033708, 0.7391987431264728, 0.510385756676558, 0.6761363636363636, 0.6972356296621325, 0.606114050558495, 0.5906921241050119, 0.6839266450916937, 0.9695121951219512, 0.9455040871934605, 0.7764127764127764, 0.8716119828815977, 0.2813141683778234, 0.256857855361596, 0.23469387755102045, 0.6083650190114068, 0.08066083576287653, 0.962962962962963, 0.3992905005912495, 0.8112359550561797, 0.21129943502824855, 0.18622300058377117, 1.0, 1.0, 0.8709677419354839, 0.6195524146054181, 0.658466819221968, 0.49683944374209865, 0.9352360043907794, 0.8778625954198473, 0.8537360890302067, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.7513416815742398, 0.3652253909843606, 0.779601406799531, 1.0, 1.0, 0.609375, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.21212121212121215, 0.0, 0.0, 0.8090909090909091, 0.5373134328358209, 0.6954314720812182, 0.6685714285714286, 0.4913793103448276, 0.6729559748427674, 0.6477987421383649, 0.6482412060301508, 0.6683937823834196, 0.528888888888889, 0.6352941176470588, 0.680473372781065, 0.4934497816593887, 0.5045045045045045, 0.6666666666666667, 0.8428571428571429, 0.423728813559322, 0.34798534798534797, 0.36, 0.41052631578947374, 0.43050847457627117, 0.460431654676259, 0.35238095238095235, 0.4080717488789237, 0.4137931034482759, 0.3973509933774835, 0.3737373737373737, 0.3894736842105263, 0.3422818791946308, 0.3612903225806452, 0.975, 0.963302752293578, 0.5706806282722513, 0.5252525252525253, 0.68944099378882, 0.6781609195402298, 0.5953307392996109, 0.5826771653543308, 0.6043956043956045, 0.9859154929577465, 0.9814814814814815, 0.8524590163934427, 0.9272727272727272, 0.31543624161073824, 0.24369747899159666, 0.26388888888888884, 0.367741935483871, 0.07792207792207795, 0.950920245398773, 0.3694581280788177, 0.20132013201320131, 0.17218543046357615, 0.15068493150684936, 1.0, 1.0, 0.49606299212598426, 0.6015473887814313, 0.605313092979127, 0.4773333333333334, 0.9225352112676056, 0.8513513513513513, 0.2136752136752137, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.7456647398843931, 0.36046511627906974, 0.7647058823529411, 1.0, 1.0, 0.5824175824175823, 0.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# word distance metric \n",
    "# calculates how many of the words on a page have changed\n",
    "# split option allows us to consider if splitting the strings into words makes a difference\n",
    "\n",
    "word_distance = []\n",
    "word_distance_split = []\n",
    "for y in range (0,len(homepages)-1):\n",
    "    first_page = homepages.iloc[y].tolist()\n",
    "    second_page = homepages.iloc[y+1].tolist()\n",
    "    seq = SequenceMatcher(None, first_page[3],second_page[3])\n",
    "    seq_split = SequenceMatcher(None, first_page[3].split(),second_page[3].split())\n",
    "    distance = 1-seq.ratio()\n",
    "    distance_split = 1-seq_split.ratio()\n",
    "    word_distance.append(distance)\n",
    "    word_distance_split.append(distance_split)\n",
    "    \n",
    "# output is the list of metric values between 0 (very similar) and 1 (very different)\n",
    "print(word_distance)\n",
    "print(word_distance_split)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
